# ARC Prize 2025 대회 정보 요약

## 대회 개요

**대회명**: ARC Prize 2025 (Abstraction and Reasoning Corpus)
**플랫폼**: Kaggle
**URL**: https://www.kaggle.com/competitions/arc-prize-2025
**대회 타입**: Featured Competition
**마감일**: 2025년 11월 3일 23:59:00
**상금**: $1,000,000 USD
**참가자 수**: 1,116팀 (2025년 10월 기준)

## 대회 목표

ARC-AGI는 AI 시스템의 **추상적 추론 능력**을 평가하는 벤치마크입니다.
각 태스크는 패턴 인식, 논리적 추론, 창의적 문제 해결을 요구하는 독특한 도전 과제입니다.

이 대회는 단순한 패턴 매칭을 넘어서, AI가 **일반화(generalization)** 능력을 갖추고
새로운 상황에 적응할 수 있는지를 테스트합니다 - AGI의 핵심 요소입니다.

## 평가 지표

### Pass@2 방식
- 각 태스크당 **2번의 예측 기회** 제공
- 정확히 일치하는 경우만 점수 획득 (**부분 점수 없음**)
- **240개 태스크** 해결 필요 (12시간 내)
  - 120개: Semi-Private Evaluation 세트
  - 120개: Private Evaluation 세트

### Grand Prize 조건
- **정확도**: Private evaluation set에서 **85% 이상**
- **효율성**: 태스크당 약 **$2.5** 계산 비용
- **상금 분배**: 85% 초과 달성한 상위 5팀이 Grand Prize 분할

### 제약 사항
- **인터넷 접속 불가** (평가 시)
- **API 호출 불가** (GPT, Claude, o3 등)
- **컴퓨팅**: L4x4s GPU (2024년 대비 2배)
- **시간 제한**: 12시간 wall-clock

## 데이터셋 정보

### 학습 데이터 (Training Set)
- **태스크 수**: 1,000개
- **예제 수**: 태스크당 2-10개 학습 예제
- **테스트**: 태스크당 1-4개 테스트 예제
- **그리드 크기**: 1×5 ~ 30×30
- **평균 색상 수**: 입력 3.8개, 출력 3.6개

**가장 흔한 그리드 크기:**
1. 10×10 (392회)
2. 3×3 (250회)
3. 9×9 (119회)
4. 16×16 (107회)
5. 15×15 (104회)

### 평가 데이터 (Evaluation Set)
- **태스크 수**: 120개
- **예제 수**: 태스크당 2-6개 학습 예제
- **테스트**: 태스크당 1-3개 테스트 예제
- **그리드 크기**: 4×15 ~ 30×30
- **평균 색상 수**: 입력 5.2개, 출력 4.6개

**가장 흔한 그리드 크기:**
1. 20×20 (29회)
2. 30×30 (26회)
3. 16×16 (22회)
4. 10×10 (21회)
5. 22×22 (20회)

### 색상 사용 분포

**학습 데이터:**
- 색상 0 (검정): 53.7% - 배경색으로 주로 사용
- 색상 8 (하늘색): 10.2%
- 색상 1 (파란색): 7.7%

**평가 데이터:**
- 색상 0 (검정): 24.2%
- 색상 8 (하늘색): 20.3%
- 색상 1 (파란색): 15.2%

**색상 팔레트 (0-9):**
- 0: 검정 (Black)
- 1: 파란색 (Blue)
- 2: 빨간색 (Red)
- 3: 초록색 (Green)
- 4: 노란색 (Yellow)
- 5: 회색 (Gray)
- 6: 마젠타 (Magenta)
- 7: 주황색 (Orange)
- 8: 하늘색 (Light Blue)
- 9: 진한 빨강 (Dark Red)

## 현재 리더보드 (2025년 10월 14일 기준)

| 순위 | 팀명 | 점수 |
|------|------|------|
| 1 | Giotto.ai | 27.08 |
| 2 | the ARChitects | 16.94 |
| 3 | MindsAI @ Tufa Labs | 15.42 |
| 4 | Guillermo Barbadillo | 11.94 |
| 5 | 1 | 10.83 |

**분석:**
- 현재 1위 점수는 27.08점 (약 27%)
- Grand Prize 목표인 85%와는 큰 격차
- 이는 AGI 수준의 추론이 매우 어려운 과제임을 보여줌
- 혁신적인 접근법이 필요함

## 태스크 구조

각 태스크는 JSON 형식으로 구성:

```json
{
  "task_id": {
    "train": [
      {
        "input": [[0,1,2], [3,4,5], ...],
        "output": [[6,7,8], [9,0,1], ...]
      },
      ...
    ],
    "test": [
      {
        "input": [[2,3,4], ...]
      }
    ]
  }
}
```

**특징:**
- 입력과 출력 그리드 크기가 다를 수 있음
- 학습 예제에서 패턴을 파악하여 테스트에 적용
- 각 태스크는 고유한 변환 규칙을 가짐

## 해결 접근법

### 1. 규칙 기반 (Rule-based)
- 패턴 매칭 및 변환 규칙 추출
- 대칭성, 회전, 반전 등의 기하학적 변환
- 색상 패턴 및 공간적 관계 분석

### 2. 탐색 알고리즘 (Search-based)
- DFS/BFS로 해답 공간 탐색
- A* 알고리즘으로 최적 변환 경로 찾기
- Monte Carlo Tree Search (MCTS)

### 3. 신경망 (Neural Networks)
- CNN: 그리드 패턴 학습
- Transformer: 시퀀스 간 관계 학습
- Vision Transformer: 이미지 수준 추론

### 4. 프로그램 합성 (Program Synthesis)
- 도메인 특화 언어 (DSL) 정의
- 학습 예제로부터 프로그램 자동 생성
- 신경-상징적 (Neurosymbolic) 접근

### 5. 메타 학습 (Meta-learning)
- Few-shot learning 기법
- 적은 예제에서 빠르게 학습
- Task-agnostic meta-learner

### 6. 하이브리드 접근
- 규칙 기반 + 학습 모델 결합
- 상징적 추론 + 신경망
- 테스트 시간 학습 (Test-time training)

## 제출 형식

```json
{
  "task_id": {
    "attempt_1": [[...]],
    "attempt_2": [[...]]
  },
  ...
}
```

- 각 태스크당 2개의 예측 필요
- JSON 파일로 제출 (submission.json)
- Kaggle API를 통한 제출 가능

## 전략 및 팁

### 개발 단계
1. **EDA**: 태스크 유형 분류 및 패턴 분석
2. **Baseline**: 간단한 규칙 기반 솔버 구현
3. **개선**: 다양한 접근법 실험
4. **앙상블**: 여러 솔버 결합

### 효율성 최적화
- 계산 비용을 고려한 모델 설계
- 캐싱 및 메모이제이션 활용
- 병렬 처리로 속도 향상

### 일반화 능력
- 과적합 방지 (Public 리더보드에 집착 금지)
- 다양한 태스크 유형에 대응
- 견고한 솔루션 개발

## 주요 도전 과제

1. **다양성**: 1000개 이상의 서로 다른 태스크 유형
2. **일반화**: 본 적 없는 태스크에 대한 추론
3. **효율성**: 제한된 시간과 컴퓨팅 자원
4. **해석 가능성**: 인간처럼 규칙을 이해하고 적용
5. **zero-shot learning**: API 없이 독립적으로 작동

## 유용한 리소스

### 공식 링크
- **ARC Prize 공식**: https://arcprize.org/
- **대회 상세**: https://arcprize.org/competitions/2025/
- **ARC 가이드**: https://arcprize.org/guide
- **체험하기**: https://arcprize.org/play

### 연구 논문
- **ARC-AGI-2 논문**: https://arxiv.org/html/2505.11831v1
- **원본 ARC 논문**: https://arxiv.org/abs/1911.01547

### 커뮤니티
- **토론 포럼**: https://www.kaggle.com/competitions/arc-prize-2025/discussion
- **공개 노트북**: https://www.kaggle.com/competitions/arc-prize-2025/code

## 개발 체크리스트

- [x] 대회 정보 수집
- [x] 데이터 다운로드 및 검증
- [x] 프로젝트 구조 생성
- [x] 환경 설정
- [x] 데이터 탐색 및 분석
- [ ] EDA 노트북 작성
- [ ] Baseline 솔버 구현
- [ ] 규칙 기반 솔버 개발
- [ ] 학습 모델 실험
- [ ] 앙상블 구현
- [ ] 효율성 최적화
- [ ] 코드 정리 및 문서화
- [ ] 최종 제출

## 주요 인사이트

1. **AGI 벤치마크**: 이 대회는 현재 AI의 한계를 드러내는 도전적인 과제
2. **창의성 필요**: 전통적인 ML 접근법만으로는 부족
3. **인간 수준 추론**: 인간처럼 추상화하고 일반화하는 능력 필요
4. **효율성 중요**: 단순히 정확도만이 아닌 계산 비용도 고려
5. **독립적 시스템**: 외부 API 없이 자체적으로 작동해야 함

## 다음 단계

1. **데이터 탐색**
   ```bash
   python3 quick_explore.py
   python3 src/data_loader.py
   ```

2. **시각화**
   ```bash
   python3 src/visualizer.py
   ```

3. **Jupyter 노트북 시작**
   ```bash
   jupyter notebook notebooks/
   ```

4. **Baseline 개발**
   - 간단한 규칙 기반 솔버 구현
   - 제출 파일 생성 및 테스트

5. **반복 개선**
   - 다양한 접근법 실험
   - 성능 모니터링
   - 전략적 제출

---

**작성일**: 2025년 10월 14일
**상태**: 프로젝트 초기 설정 완료
**다음 목표**: EDA 및 Baseline 모델 개발
